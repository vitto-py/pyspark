{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4912a127-ba0f-44b6-ad11-7373dae5e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a8d56f-580d-41e8-83d9-d7d24e4002f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/05 23:13:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/05 23:13:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"ch01\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aeecd65-434a-40dc-923c-1dbaf4460721",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = '''`CallNumber` INT, \n",
    "`UnitID` STRING, \n",
    "`IncidentNumber` INT, \n",
    "`CallType` STRING, \n",
    "`CallDate` STRING, \n",
    "`WatchDate` STRING, \n",
    "`CallFinalDisposition` STRING, \n",
    "`AvailableDtTm` STRING, \n",
    "`Address` STRING, \n",
    "`City` STRING, \n",
    "`Zipcode` INT, \n",
    "`Battalion` STRING, \n",
    "`StationArea` STRING, \n",
    "`Box` STRING, \n",
    "`OriginalPriority` STRING, \n",
    "`Priority` STRING, \n",
    "`FinalPriority` INT, \n",
    "`ALSUnit` BOOLEAN, \n",
    "`CallTypeGroup` STRING, \n",
    "`NumAlarms` INT, \n",
    "`UnitType` STRING, \n",
    "`UnitSequenceInCallDispatch` INT, \n",
    "`FirePreventionDistrict` STRING, \n",
    "`SupervisorDistrict` STRING, \n",
    "`Neighborhood` STRING, \n",
    "`Location` STRING, \n",
    "`RowID` STRING, \n",
    "`Delay` FLOAT'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c350a4-7472-4002-b597-9c3ec2559e96",
   "metadata": {},
   "source": [
    "> **DataFrameReader**, that enables you to read data into a DataFrame from myriad\n",
    "data sources in formats such as JSON, CSV, Parquet, Text, Avro, ORC, etc. Likewise,\n",
    "to write a DataFrame back to a data source in a particular format, Spark uses\n",
    "**DataFrameWriter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ade567b-887a-4f17-a2fd-921a0c941f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_fire_file = \"./learning-spark-v2/sf-fire/sf-fire-calls.csv\"\n",
    "fire_df = spark.read.csv(sf_fire_file, header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7c6683-43c5-4710-8d71-785e2b0ec797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/05 23:16:07 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         null|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         null|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         null|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         null|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         null|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fire_df.printSchema())\n",
    "fire_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638174ba-5466-47da-9478-d75401cd7b6b",
   "metadata": {},
   "source": [
    "> Parquet, a popular columnar format, is the default format; it uses\n",
    "snappy compression to compress the data. If the DataFrame is written as Parquet, the\n",
    "schema is preserved as part of the Parquet metadata.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121414b1-e180-4504-837f-2a372722ce50",
   "metadata": {},
   "source": [
    "# Transformation in Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42f3a57-30e0-4358-9cf2-a3ed67c8e8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_fire_df = (fire_df\n",
    ".select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\")\n",
    ".where(col(\"CallType\") != \"Medical Incident\")) # select where not\n",
    "few_fire_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c888fb-6d5e-4307-b61a-ab9004714278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all possible Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6427a6de-1eef-4019-8573-1f95b19e1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "753610bd-d678-4c79-99cb-9cccfc08c141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               30|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use () for multi-line\n",
    "(fire_df.select(\"CallType\")\n",
    ".where(col(\"CallType\").isNotNull())\n",
    ".agg(F.countDistinct(\"CallType\").alias(\"DistinctCallTypes\")) #countDistinct\n",
    ".show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b291502-4ec3-4b72-8199-3ac64b276902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               30|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# or one line\n",
    "fire_df.select(\"CallType\").where(col(\"CallType\").isNotNull()).agg(F.countDistinct(\"CallType\").alias(\"DistinctCallTypes\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05499aaa-fc3b-4bca-b184-348837cce14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|CallType                     |\n",
      "+-----------------------------+\n",
      "|Elevator / Escalator Rescue  |\n",
      "|Aircraft Emergency           |\n",
      "|Alarms                       |\n",
      "|Odor (Strange / Unknown)     |\n",
      "|Citizen Assist / Service Call|\n",
      "|HazMat                       |\n",
      "|Explosion                    |\n",
      "|Oil Spill                    |\n",
      "|Vehicle Fire                 |\n",
      "|Suspicious Package           |\n",
      "+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_df\n",
    ".select(\"CallType\")\n",
    ".where(col(\"CallType\").isNotNull())\n",
    ".distinct()\n",
    ".show(10, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ff14845-010a-4909-ad65-818b04615ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|ResponseDelayedinMins|\n",
      "+---------------------+\n",
      "|5.35                 |\n",
      "|6.25                 |\n",
      "|5.2                  |\n",
      "|5.6                  |\n",
      "|7.25                 |\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename a column\n",
    "new_fire_df = fire_df.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "(new_fire_df\n",
    ".select(\"ResponseDelayedinMins\")\n",
    ".where(col(\"ResponseDelayedinMins\") > 5)\n",
    ".show(5, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46532b-2b7f-405e-a267-0f1fa220e4e6",
   "metadata": {},
   "source": [
    "> the columns CallDate, WatchDate, and AlarmDtTm are strings\n",
    "rather than either Unix timestamps or SQL dates, both of which Spark supports and\n",
    "can easily manipulate during transformations or actions <br>\n",
    "> spark.sql.functions has a set of to/from date/timestamp functions such as to_timestamp() and to_date() that we can use for just this\n",
    "purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c06dc48a-be71-43f3-86cf-be181128dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_ts_df = (new_fire_df\n",
    ".withColumn(\"IncidentDate\", F.to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\"))\n",
    ".drop(\"CallDate\")\n",
    ".withColumn(\"OnWatchDate\", F.to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\"))\n",
    ".drop(\"WatchDate\")\n",
    ".withColumn(\"AvailableDtTS\", F.to_timestamp(col(\"AvailableDtTm\"),\n",
    "\"MM/dd/yyyy hh:mm:ss a\"))\n",
    ".drop(\"AvailableDtTm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a31760-9d2e-417f-9f93-ed8a732c40cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTS      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_ts_df.select(\"IncidentDate\", \"OnWatchDate\", \"AvailableDtTS\").show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc5d981-9903-4184-923b-f0734c8e56f7",
   "metadata": {},
   "source": [
    "> Now that we have modified the dates, we can query using functions from\n",
    "spark.sql.functions like month(), year(), and day() to explore our data further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48245b62-5f48-4c93-805d-8af92595c739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              2000|\n",
      "|              2001|\n",
      "|              2002|\n",
      "|              2003|\n",
      "|              2004|\n",
      "|              2005|\n",
      "|              2006|\n",
      "|              2007|\n",
      "|              2008|\n",
      "|              2009|\n",
      "|              2010|\n",
      "|              2011|\n",
      "|              2012|\n",
      "|              2013|\n",
      "|              2014|\n",
      "|              2015|\n",
      "|              2016|\n",
      "|              2017|\n",
      "|              2018|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df\n",
    ".select(F.year('IncidentDate'))\n",
    ".distinct()\n",
    ".orderBy(F.year('IncidentDate'))\n",
    ".show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f379b9b1-8ff7-417a-a6d0-eeae1414a323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
